1.理论分析
2.现状分析
3.启动优化
4.线上验证
5.防劣化

1.理论分析:启动全路径分析以及耗时成因归结
	1.全启动路径分阶段耗时分析
		从全路径出发可以让视野更加开阔
		
		全路径分析：用于发现启动各阶段的潜在耗时点
		应用启动过程整体分为两大阶段和两个间隙，它们按时间顺序排布为：Application 阶段、handle message 间隙、Activity 阶段和数据加载间隙
		
		1.Application 阶段分析：
			1.app进程由zygote孵化出来后，首先会执行ActivityThread的main方法，这里可以看成是单个进程的入口方法，和java中的main方法一样。
			2.在main方法中，会创建消息循环和主线程Handler，接着会调用AMS的attachApplication并传入当前应用的binder对象，用于AMS和当前应用进程交互。
			3.AMS的attachApplication中会创建一个ProcessRecord用于记录当前进程状态。并回调thread.bindApplication的方法，将当前进程状态信息传递给应用进程。
			4.应用进程在受到AMS的bindApplication方法后，将进程信息存储在一个AppBindData对象中，并使用Handler传递，最终会执行到ActivityThread的handleBindApplication。这个时间点就可以看做是应用进程启动开始时间
			5.在handleBindApplication中调用 data.info.makeApplication()，这个方法内部会创建应用context且使用反射创建Application，并依次调用Application的attach，attach方法会调用attachBaseContext方法，这也是应用的最早加载时机。
			6.在handleBindApplication中makeApplication创建application后，会继续执行installContentProviders，这个方法内部执行installProvider，
			6.installProvider方法中会使用反射创建进程中的ContentProvider，也就是清单中的ContentProvider。并回调ContentProvider对象的attachInfo，在attachInfo中会将清单中的属性赋值给当前ContentProvider对象，
			并调用ContentProvider的onCreate方法。很多三方sdk在这里进行一些初始化操作，可能导致启动耗时的不可控，需要按具体case优化。
			7.最后执行application的onCreate方法。这里是很多三方库和业务初始化之处，也是启动优化最主要优化点，可通过异步，按需，预加载等方式进行优化。
		以上就是Application阶段的启动过程
		2.handle message间隙：
			在Application阶段和Activity阶段之间可能会插入一些post到主线程的任务，需要加以监控或者通过消息调度来缩小该间隙
		
		3.Activity阶段：
			1.回到Application步骤分析3：AMS回调thread.bindApplication的方法后，在bindApplication的方法执行完成后，会继续回调mStackSupervisor.attachApplicationLocked(app)
			这个方法中：获取当前进程的第一个非LauncherActivity，然后调用realStartActivityLocked去启动根Activity。
			
			2.然后就是创建Activity，并执行Activity生命周期，OnCreate方法是首屏业务优化的主要场景也是开启并发的主要时机，其中会执行setContentView，这里会触发DecorView 的 install，去解析xml数据，并转换为View。这里是一个耗时操作。
			可采用异步 Inflate 配合 X2C（编译期将 xml 布局转代码）并提升相应异步线程优先级的方法综合优化
			
			3.最后就是View的渲染操作，包括View的三大measure，layout，draw。可尝试从层级，布局，渲染上取得优化收益。
		4.数据加载阶段
			该阶段可以使用预加载，缓存或者网络优先级调度等手段进行优化，对非首屏数据，延迟加载或者按需加载。
		
		对启动全路径还可以使用通用性的优化手段：如启动任务调度框架，类重排，IO预加载，全局通用性框架优化等
	2.启动耗时成因分析：
		首先需要了解这里所说的耗时指由于代码设计的不合理导致多消耗了很多系统资源。而不合理的耗时点正是需要做耗时归因分析之处。
		这里可以分为以下几种：
		1.CPU Time：指占用的CPU时间片.
			比如：
			1.循环操作，这就是一个比较常见的耗时点，可以考虑使用更优化的手段或者一定算法替换循环，以减少循环所占用的CPU时间片。
			2.反射操作，反射操作也是我们开发中经常需要使用到的地方，反射耗时主要是通过字符串去查找Field或者Method。对于需要大量使用反射的地方，可以采用缓存机制或者方法内联的方式进行优化
			3.类加载：类加载过程主要耗时点在包括：
				Load ：从Dex文件中读取类信息，可通过类重排的方式进行优化
				Verify：验证指令的合法性，通过关闭Class Verify可以优化该过程，同时高版本的 vdex 也是为了优化 verify 过程而设计，在 dex2oat 的时候做 verify，verify 之后的结果保存成 vdex，后续只需要加载 vdex
				Link：给 Field、Method 分配内存，按照名字排序以方便后续反射的时候查找 Field、Method 等，这个过程的优化，art 虚拟机采用了 ImageSpace 的方案进行了优化，将 Link 后的内存保存为 image 文件，后续可以直接 load 这个 image 文件，省去了 Link 过程
		
		2.CPU Scheduler：指主线程在可执行状态下获取不到时间片，这种情况比较少见因为本身主线程优先级就比较高，但是需要注意View的渲染过程:View的渲染使用了RenderThread 
		而RenderThread用于提交CPU命令给GPU，而 优先级并没有主线程那么高，流畅度会有一定影响，优化手段还是从降低CPU负载考虑，比如业务降级或者业务打散等手段。
		
		3.IO Wait ：指发生了IO操作需要等待IO返回，这类耗时一般发生在资源和文件的读取，类加载等时刻
		Resources相关耗时：主要是需要从Apk中读取资源文件，优化策略：异步加载，资源重排，预加载等，类的加载和资源加载类似，也可以通过类的重排，预加载等手段进行
		文件读写耗时：这里文件分为系统文件和业务文件，业务文件是指业务逻辑需要的文件读写，可以使用异步加载的方式解决，而系统文件指dex的读写，优化手段还是从类重排和预加载
		
		4.Lock Wait：指主线程处于等锁状态，等待被其他线程唤醒或者超时唤醒自己的过程。
		这里也可以分析业务锁和系统锁：业务锁主要是主线程等待的业务逻辑未能及时处理完，优化思路：移除业务锁或者加快业务逻辑处理。
		系统锁主要有：String InternTable Lock，ClassLinker Lock，GC Wait Lock
		
		5.IPC 指进程间通信，操作系统大都含有相应的机制，Android 中所特有的 IPC 机制是 Binder，由于进行 IPC 调用往往需要等待通信结果本质上这也算是一种 Lock Wait，但 Android 特有 Binder 机制所以单独列出，这类耗时可采用减少或替代 Binder 调用等手段来优化
		
		
		综合前述的五大耗时成因，这里举一个分析启动阶段 UI 耗时成因的例子作为实践参考，根据 UI 界面的生命周期（一般划分）——UI 构建、数据绑定、View 显示三个阶段分别进行分析：
		 1.在UI 构建阶段中首先要对界面布局的 xml 文件进行解析，这会导致 IO Wait 耗时，在接下来要解析 xml 文件中的 TagName 从而获取对应 View 的 class 会用到反射、创建各子 View 实例并生成 View 树又会用到循环递归，两部分都会增加 CPU Time 的开销
		 2.然后是数据绑定阶段，该阶段主要分两部分，一部分是对数据做请求、解析、适配，另一是部分是将适配好的数据填充进 UI 中，前一部分往往会涉及到 Json 解析成 Data Class 实例，这里就可能涉及反射、循环遍历嵌套的数据类结构等增加 CPU Time 的操作
		 3.最后是View 显示阶段，常见的 measure、layout、draw 三大渲染 View 的步骤就在其中，它们同样会产生递归遍历父子 View 的耗时，此外这里还涉及将应用层计算好的渲染 View 的数据传递给系统层做最终的像素点排布，那么必然又会产生 IPC 耗时。
		从这个例子可见即使再复杂的场景只要我们进行细粒度的分析，都能将耗时点归入前述某一成因中。

		
2.现状分析:当前应用耗时现状分析
	耗时现状分析可以分为：线下 Profile 数据与线上监控数据的对照分析
	
	线下 Profile 数据分析：指使用性能探测工具抓取应用启动路径各阶段耗时和系统资源消耗情况
	常见的Profile工具有：TraceView，Systrace，AndroidProfiler等
	还有可以考虑抖音自研的工具 RheaTrace：通过该工具我们可以在线下抓取整个启动路径的 Trace 文件，其整体样式与 Systrace 一致，但是涵盖了更多的信息点，一个样例 Trace 文件如下图所示：
	使用Profile工具注意点：
	1.抓取trace一定要基于release包，debug包中通常涵盖了一些调试信息，会影响启动性能。
	2.查看profile数据时首要查看主线程，寻找其中不符合预期的耗时方法，而预期的阈值可以根据应用自行设定，抖音将主线程耗时在5ms以上的方法认定是不符合预期
	3.逐个分析耗时原因，寻找突破口。耗时原因需要结合方法实现逻辑以及诸多运行时信息综合分析（这里可以参考 Google 官方文档“浏览 Systrace 报告”）
	需要关注的运行时信息有方法执行时段对应的 CPU 负载、线程状态的颜色标识值、锁信息、IO 耗时、Binder 调用耗时等，根据这些信息判定引起方法耗时的主要原因，再结合理论分析中不同阶段、不同系统资源类型探寻优化手段
	
	线上监控数据分析：
	这部分数据分析主要用于参照和补充：
	参照：指线下Profile分析出的耗时点要对照线上数据确认其在大盘中存在普遍现象。
	补充：指现象Profile未分析出的耗时点可能在线上出现。
	如何对线上的启动性能指标做监控
	下面将对这部分做详细阐述，分为启动性能指标的定义、统计和校准三部分：
	
	启动性能指标定义：启动指标定义主要在于如何确定启动路径的起点与终点。
	
	起点的备选项有下图中的三个点以及 Application 的 attachBaseContext 方法
		1.下图中“点击图标”后的/proc/self/stats starttime 是内核中记录的 App 启动时间点，该数据的 Android 版本兼容性良好也比较贴合真实情况，可以作为备选；
		2.接下来的 Process.getStartElapsedRealTime 是 Framework 中记录的 APP 进程创建起点，该 API 是 Android N 起才提供的兼容性较差；
		3.再往后是 Application 的构造函数，按照 Android 官方生命周期式的开发模式通常不会往 Application 的构造函数中加逻辑，所以不建议在这里记录起点；
		4.最后是大家熟悉的 attachBaseContext 方法也是 Application 生命周期中非常早的一个点，可以在这里记录启动点，虽然可能和真实情况有小幅差距，但能够起到基本的对照效应并且处于 APP 逻辑可以干预的范围内，抖音的启动路径起点选定的正是此处，此外也可以结合前述的内核中启动时刻综合观测。
	而关于终点的定义同样有几个备选项：Activity-onResume、Activity-onWindowFocusChanged、View-dispatchDraw 和 DecorView-post：
		1.少数 APP 在选定冷启阶段终点时可能会选择首页 Activity 的 onResume 时机，但此时整个 Activity 还不是完全可见，与用户感受到的冷启阶段结束时刻有一定的差距；
		2.基于上述原因，更多 APP 会选择首页 Activity 的 onWindowFocusChanged 时机，抖音也是选择的此时机作为冷启过程的终点，此时首页 Activity 已经可见但其内部的 view 还不可见，对于用户侧已经可以看见首页背景，即认为冷启阶段到此结束，后续的首页内 View 绘制归入首刷过程中；
		3.dispatchDraw 从 View 可见这个角度讲应该是比较接近用户感受的，但其受业务改动影响较大，不利于把控冷启时间及维护；
		4.最后是通过 DecorView 在 attachToWindow 前 post 一个 runnable 来打点的方式，该方式可以保障在业务 View 完成渲染后做打点，但该方式可能会受业务同学做懒加载在打点前插入逻辑的影响，因此抖音的冷启终点也未选用该时机。

	启动性能指标统计：
	在统计性能指标时有个关键点往往被大家忽略，就是分位值的概念，由于平均值相对更通俗易懂且对大盘突发问题敏感往往作为首要统计指标被关注，但其存在波动较大不利于大盘监控以及难以体现不同分位机型启动性能差异的问题，而分位值更有利于全面监控且各分位波动相对较小，此外对于低端机的性能问题能够更好地显现出来，有助于做专项优化，在优化抖音的启动性能时我们会重点关注 50 分位和 90 分的性能指标，不过分位值也存在一些缺点，比如：概念理解起来相对复杂、个别 bad case 分散到各分位不容易体现出来等，因此比较好的实践是：日常优化主要统计分位值，平均值作为辅助完善监控体系。
	
	启动性能指标校准：
	于启动路径往往比较复杂，因此添加了启动性能埋点后还需要额外的校准，总的原则是需要保障指标数据能切实反映大盘用户情形。在添加客户端埋点时最好是先梳理再分主路径和重点 case 分别打点，此外还要对若干异常 case 的数据进行剔除或分类避免污染打点数据，比如抖音在添加启动时间打点时就会对开屏广告、保活进程、push 拉起、deeplink 拉起、启动期间退后台、新用户启动等场景进行过滤或分开统计。

	
3.启动优化实践
	经过理论分析和现状分析就可以进行具体启动优化了。
	优化方向：
	主线程优化，后台线程优化，全局优化

	主线程优化：需要在全路径各阶段中细化具体的耗时成因：如CPU Time，Cpu Scheduler，IO Wait,Lock Wait.
	完成耗时归因后可以使用逐步升级的优化策略来逐个击破。
	对于首屏所必须的的耗时逻辑做正面优化（可使用缩短耗时逻辑，异步并发，延迟加载等手段）
	对于非首屏必须的的耗时逻辑做按需要加载
	对于优化后扔存在的耗时任务做降级处理（大都有损，需评估全局收益）

	后台线程优化：策略与主线程类似，在此基础上还可以实施任务缩减，线程收敛，开启多进程等优化措施。
	此外主线程和后台线程一般存在多种任务，且彼此之间可能还存在关联关系，所以需要梳理全局任务依赖并做精细化的任务重排，旨在减少任务间依赖等待。

	全局优化：主要是指与业务无关的通用的全局优化策略。如虚拟机层面或者IO层面的优化等。
	
	
	在开始落地各个优化措施之前还有很重要但往往会被忽略的一步——按优先级排布优化项、制定整体优化方案，这一步在很大程度上制约着后续启动优化的收益预期与进展把控，这两点对于按时达成启动优化的终极目标都至关重要。前述中提及了对“优先级”的把控，这点是制定整体优化方案的重中之重。
	从抖音启动优化实践总结来看比较好的优先级策略是按照“投入产出比”来排布优化项，顾名思义：投入人力越少但优化幅度越大的优化项越应该排在前期，因为所有的性能优化历程都势必会经历从高收益到低收益的变化，那么相应的在排布优化项的前后顺序时也需顺应此规律，最终呈现的态势即为：前期以小成本快速降低大盘启动耗时，后期逐步提高投入突破各个瓶颈型耗时点（更后期大规模重构仅能减少几十毫秒启动时间的情形也应在预期之内），全过程同期加强防劣化机制，最终做到可持续优化。
	
	在完成前述的全局优先级排布及方案制定后，才算真正来到了实施优化的阶段，在这个阶段所要用到的各类优化策略及配合方法在前文方法论部分已有详细讲述，在实战部分首先要补充一下前述几类优化策略按照“性能无损”、“业务无损”的区别划分，整体如上图所示，此外，我们会结合抖音启动优化实战经验列举各优化策略下可实施的优化项，以供参考：

	正面优化：删减非必要的启动逻辑、开屏页与首页 Activity 合并、获取进程名从 IPC 转反射方式等
	按需优化：ContentProvider 中过早初始化逻辑转为使用时初始化、多进程由启动时加载转为使用时或特定场景触发加载等；
	延迟优化：4.x 机型延迟执行 Multidex.install 中的 Odex 操作、主线程消息队列中非启动必要消息延迟执行、启动路径非高优业务逻辑延迟初始化等；
	运行时优化：CPU 提频、语言层面优化（内联、替换反射、避免用 Kotlin 的 Range 循环）、关闭 Verify Class、4.x 机型抑制 GC、主动触发 AOT 编译、资源重排、类重排、dex 重排等；
	异步优化：异步预加载（ShardPreference、实例化对象）、异步 inflate view、线程收敛等；
	降级优化：极速版、组件化降级、非必要耗时逻辑按人群/地区降级等；
	综合优化：启动任务调度框架、启动路径重构、前后台启动任务精细化重排、后台负载优化等，这些优化项属于前述优化思想的综合应用，一般不局限于单方面的优化。
	
	通过上述列举的各策略优化项你可能会发现，这其中有的优化项其实会对个别业务性能或功能有损，但最终对于启动性能是有显著提升的，那么此时需要按照“全局收益最大”的策略来综合评估这些优化项的可落地性，并不是只看单点的得失，这种全局性的思维在性能优化中非常重要。
4.线上验证
	经过了前面几个步骤就到了线上验证大盘收益的阶段了，这个阶段需要注意三个点
	1.线下的优化一定要有线上的指标反馈
	线下的优化由于设备的局限性和用户操作习惯差异，难以评估是否具备普遍影响，只有当线上指标取得正面反馈的时候，才能验证拿到有效的优化收益
	2.线上指标需要结合均值与分位值综合来评估
	只关注启动耗时的均值往往会掩盖低分位设备的现状，这部分设备可能占比不高，对均值影响有限，但抖音庞大的用户基数乘以该比例仍旧是不小的数量，为了保障该部分用户的启动性能体验，抖音一般会分 50%、70%、90%三个分位值来评估指标；
	3.在验证收益时通过 AB 实验达成
	这样做不仅能控制变量确保优化项的严格有效，还能借此来观察性能优化所带来的业务指标收益，这些都可以作为规划后续启动优化方向的参考指导
	
	针对三个关键点在落地时的技巧或注意事项加以补充：
	线下的优化一定要有线上的指标反馈：由于线上设备的固有硬件性能各异，所以需要有足够量级的用户启动打点数据才能相对准确地判定线下的优化是否在线上产生了效果，这个量级从抖音启动优化中摸索的经验来看一般达到 100 万即可；此外，观测启动性能数据的时间点也需要把控好，这是由于每次发布升级版 APP 后，大都是性能相对好的手机会先升级，这个现象会等导致发版初期的启动性能数据整体偏好，不能反映真实大盘情形，因此，抖音一般会选取每个版本发版后 4-5 天（可能随 APP 升级覆盖安装的速度不同而不同）的数据判定大盘情形。
	
	线上指标需要结合均值与分位值综合来评估：在抖音启动优化实践中，启动耗时均值会更多用于大盘情形评估或线上监控中，而作为性能优化的同学最主要关注的是 50 分位机型的数据，这是能代表过半数用户启动性能水准的指标，此外 90 分位以上的机型也需要我们额外关注，这类机型非常容易放大启动性能问题，从实际来看，90 以上相对 50 的绝对分位数差了不到一倍，但冷启耗时却可能差到 2 倍左右（如下图所示抖音在某段时期的各分位冷启耗时情形），这说明低端机的用户启动体验是明显可感知的差，基于我们曾经做过的劣化实验结果来看，这些机型的启动性能如果不能有效提升，将有很大概率减少其留存。

	在验证收益时通过 AB 实验达成：AB 实验相对于观测不同版本的大盘数据来看更具有严谨性，因此在产出实验结论前同样需要保障数据量和时间跨度，抖音在开启性能的 AB 实验后，一般会让对照组及实验组进组用户各达到 100 万并保持至少 5 天后才进行实验的数据分析并产出结论，这样可以基本保障所有相关指标的稳定及置信。
	
5.防劣化
在线上验证优化措施取得切实收益后，并不是万事大吉了，持续保持住优化效果才算完整达成了启动性能优化的目的。其实不仅是启动优化，整个性能优化领域都是围绕着“攻”和“守”来展开的，“攻”即为前述的分析与优化，而“守”则是防止劣化，在防劣化方面大家往往不会像优化的方面那么重视，但实际上能防止劣化是可持续取得优化效果的前提（否则新的优化效果会用于弥补劣化甚至入不敷出），并且防劣化相比于优化是更能持久有益的。

抖音启动性能防劣化的进程分为了三个时期，不同时期有不同的表现与应对手段，这很可能是大多数 APP 优化启动性能都要经历的，这里提炼出来以供参考：
1.快速下降期：此时一般位于启动优化的初始阶段，优化空间很大，伴随有小幅度的劣化但往往都能被更大幅度的优化抵消且还仍有收益，这时应该抓大放小，按照更高投入产出比的策略重点推进优化，同时也抽出少部分精力治理修复成本低的劣化。
2.瓶颈期：到了该时期绝大部分优化收益已经拿到，想进一步做到优化往往需要投入更多成本，且优化幅度有限，整体的投入产出比不高，同期还会伴随有中小幅的劣化，此时需要建立完善的线上线下监控体系，及时发现并修复劣化，此外还要通过架构改造从源头上限制劣化的发生，综合保障优化的收益不会被劣化抵消。
3.劣化期：这个时期往往出现在年关或重要节日期间，这类时间点往往有重要且紧急的活动项目上线，众多关联方面均要为其开绿灯，启动性能指标也不例外，为了保障活动效果可能要加入若干耗时的主线程启动任务，所带来的的劣化幅度往往比较大，此时需要对齐预期并在活动结束后及时修复。

防劣化的体系建设是个比较复杂的工程，要做好是有非常大的挑战的。抖音从最早的线下手动的分版本测试开始，经过了逐步的摸索优化，演变到当前涵盖了代码提交时静态检测、线下自动化劣化测试和归因、灰度劣化发现和归因、线上常态化的劣化监控和归因。防劣化是一个漏斗，从代码提交阶段到线下测试阶段，再到灰度发布阶段，再到线上版本发布阶段，我们希望劣化能够更前置的发现，每个环节都尽可能的发现解决更多的劣化，保证更少的劣化被带到线上。

防劣化的有几个难点：一是劣化检测的准确率和召回率，为了更多更准确的发现劣化；二是劣化的准确归因，发现劣化之后，如果不能精准的指出劣化的原因，需要投入比较多的人力资源和时间定位劣化原因，影响劣化解决的效率；三是劣化的修复，如果是比较严重的劣化，可以采用阻塞发版限期解决的方式，是比较容易推进解决的。但是从抖音的实践来看，当启动优化到了深水区之后，优化的速度已经比较缓慢，需要关注几十毫秒级别的劣化了，假设我们解决了一二两个难点，发现了这些轻微的劣化，但是如何推进业务去解决这些小劣化也同样是一个难题。我们需要能够量化出这些劣化对业务的影响，针对不同的劣化量级，和业务对齐优先级，确定标准的劣化修复流程，才能够保证劣化不会被带到线上影响大盘用户。

防劣化是一个长期的工作，抖音投入已经有一年多了，目前整体效果还不错，在这个过程中也积累了比较多的经验，之后会专门写一个抖音的防劣化系列文章来给大家介绍我们的技术成果。

启动优化工具
古人云“工欲善其事必先利其器”，在启动性能优化领域也是一样，我们不仅需要趁手的工具来定位优化耗时问题，还需要尽量自动化的工具来持续发现劣化问题，也就是说整个启动优化在“攻”和“守”的两大方面均需要工具的辅助。那么下面将针对这两部分的工具分别进行介绍及分享抖音在启动优化工具方面的探索：

线下分析工具:
这部分主要针对业界常见的 APP 性能探测工具进行基本原理解析及优缺点对比，具体包含的工具有：TraceView、CPU Profiler、Systrace，此外还将提及抖音自研的“新一代全能型性能分析工具 RheaTrace”：
	TraceView：Instrumentation 模式下采用 AddListener 的方式注册 MethodError、MethodExited、MethodUnwind 的回调来采集方法起止时间；Sampling 模式下使用一个 SamplingThread 定时主权线程堆栈，通过对此的堆栈对比近似确定函数的进入和退出时间；虽然是官方提供的工具，但两种模式本身都存在比较大的性能损耗，可能带偏优化方向；
	CPU Profiler：整体通过 JVM Agent 实现，具有完成方法调用栈输出，且支持 Java、C/C++方法的耗时检测，上手比较简单，但其同样存在性能损耗较大的问题，且一般仅用于 debug 包，release 包需要额外添加 debuggable 的配置；
	Systrace：基于 Android 系统层的 Atrace 实现，Atrace 又基于 Linux kernal 层的 ftrace 实现，ftrace 在内核中通过函数插桩获取耗时；其自身性能损耗比较低、数据源丰富且具有较好的可视化页面，但其默认监控点较少，在 APP 自有代码中的监控点需要手动加入，比较麻烦；
	RheaTrace：这是抖音基于字节码插桩结合 Systrace 及 Atrace 自研的工具，其具有自动加入监控点、各类耗时信息全面、性能损耗低等特点，是抖音日常在线下实施性能优化时首选的工具，其细节详见前述公众号文章，这里不再赘述。

RheaTrace 目前是抖音性能优化同学的主要工具，它不仅仅是一个工具，也是一个平台。除了 Systrace 自带的性能数据之外，我们增加了业务的函数耗时插桩的数据，可以更全面地对耗时进行分析。但是这些数据还不够，我们支持以插件的形式，增加自己定制的数据，比如为了优化 IO 的耗时，我们通过 hook 增加了更精细化的 IO 的信息，辅助定位 IO 的耗时问题；抖音的类加载耗时也是有些严重，我们也 hook 了类加载，增加了类加载的性能数据。我们要极致地优化抖音启动时间，以上这些数据是不够的，还有锁、View 耗时信息等相关数据补充，给性能优化的同学提供全方位的性能分析工具

除了 RheaTrace 之外，还有一些特定场景的小工具，比如线程分析工具、内存分析工具、高频函数分析等。由于篇幅有限，就不在这里一一介绍，后面会有专门的系列文章来介绍。

线上监控工具:
上面介绍启动优化方法论的时候我们提到了，不能只是看线下的性能分析，线下的分析结果并不能完全代表线上大盘用户的情况。我们分析线上的性能数据，一方面能够验证我们的线上优化效果，另一方面能够从线上多个维度的数据里指导后续的优化方向

线上监控工具和线下的差异点主要在低性能损耗和兼容性，我们将 RheaTrace 做了改造，使其能够满足线上的监控要求。性能损耗上，我们将监控的性能损耗控制在 1%以内，包大小控制在 200KB 以内，基本实现了线上全量用户的启动耗时监控。通过启动路径的全量插桩，可以针对启动路径的各个阶段进行监控，一是可以发现线上用户哪些任务比较耗时，可以针对性的优化，让更多用户受益；二是可以监控线上的启动任务，如果发生了耗时增加，那么说明有劣化，这比监控到启动时间的劣化，要更容易定位到原因。除了线上的全量慢函数监控之外，我们的线上启动监控还会细化IO、锁、GC等多种维度的耗时数据，帮助定位线上为什么耗时慢，提供新的优化方向。

总结一下线上启动监控工具的思路就是：将线下的性能分析数据，低损耗的移植到线上，观察线上用户的性能数据，线上线下相结合的分析启动耗时，为启动优化提供优化方向指导。

启动性能优化之路去向何方:

看了上文关于启动性能优化如此多的理论与实践，想必你已经意识到启动优化之路注定是不会平凡的，抖音在这条路上探索了 2 年之久且仍未到达尽头。在这条路上势必会经历前期的坦途、中期的迷茫与后期的瓶颈，但无论如何都要一直坚定地走下去，因为只要业务还有一天在迭代那么启动性能就有一天存在挑战的可能，所以启动优化之路的未来必然是无尽头的。
既然如此，那么我们的重点就应该从何时才能走完这条路转移到如何走得更精彩之上，甚至到最后能够做到把控这条路的走向，这或许也能算作另一种意义上的走完启动优化之路，那么什么才算走得更精彩以及把控路的走向呢？
迷茫时慢下步子再分析全局的耗时点寻找到新的优化策略、遇到瓶颈时先暂时放缓追赶指标尝试从代码重构上挖掘深层的收益、不断开拓跨领域（如端上智能降级）结合的优化方向……这些或许都能称作是一种精彩，并且会因人而异，最终，当这种精彩累计得足够多之时我们很可能会发现启动优化之路上已知的所有岔路口全被走了个遍，同期 APP 的启动性能也很可能已经达到了再优化也没什么明显业务收益的地步，并且出现的任何劣化点都能及时被解决掉，那么这时不出意外的话，启动优化之路走向的把控权已经尽在你手中了。




